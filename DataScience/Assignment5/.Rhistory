validate_lrm(0.9)
validate_lrm(0.75)
validate_lrm(0.6)
data_size = dim(Default)[1]
train = sample(data_size, data_size * 0.75)
glm_fit = glm(default ~ income + balance + student, data = Default,
family = "binomial", subset = train)
prob = predict(glm_fit, newdata = Default[-train,], type = "response")
predictions = rep("No", length(prob))
predictions[prob > 0.5] = "Yes"
conf_mat = table(predictions, Default[-train,]$default)
print(conf_mat)
res_err = (conf_mat[1, 2] + conf_mat[2,1]) / length(predictions)
print(res_err)
rm(list = ls())
library(ISLR)
attach(Default)
set.seed(1)
# a. Logistic regression model using "income" and "balance".
glm_fit = glm(default ~ income + balance, data = Default, family = "binomial")
print("Logistic Regression Model Summary using income and balance")
print(summary(glm_fit))
# b. Use Validation set approach and estimate the test error of this model.
validate_lrm = function(split_ratio) {
print(paste0("Model validation for Default data set using split ratio = ", split_ratio))
data_size = dim(Default)[1]
train = sample(data_size, data_size * split_ratio)
glm_fit = glm(default ~ income + balance, data = Default,
family = "binomial", subset = train)
prob = predict(glm_fit, newdata = Default[-train,], type = "response")
predictions = rep("No", length(prob))
predictions[prob > 0.5] = "Yes"
conf_mat = table(predictions, Default[-train,]$default)
print(conf_mat)
res_err = (conf_mat[1, 2] + conf_mat[2,1]) / length(predictions)
print(res_err)
}
# Assuming 50/50 to be the split for validation set approach.
validate_lrm(0.5)
validate_lrm(0.9)
validate_lrm(0.75)
validate_lrm(0.6)
# d. Logistic Regression model for Default data set using income, balance and student.
#    Considering split ratio as 75/25
print("Model validation for Default data set with student, income and balance using split ratio = 0.75")
data_size = dim(Default)[1]
train = sample(data_size, data_size * 0.75)
glm_fit = glm(default ~ income + balance + student, data = Default,
family = "binomial", subset = train)
prob = predict(glm_fit, newdata = Default[-train,], type = "response")
predictions = rep("No", length(prob))
predictions[prob > 0.5] = "Yes"
conf_mat = table(predictions, Default[-train,]$default)
print(conf_mat)
res_err = (conf_mat[1, 2] + conf_mat[2,1]) / length(predictions)
print(res_err)
source('~/Git/Homework/DataScience/Assignment4/pasatra_question5a.R', echo=TRUE)
source('~/Git/Homework/DataScience/Assignment4/pasatra_question5a.R', echo=TRUE)
source('~/Git/Homework/DataScience/Assignment4/pasatra_question5a.R', echo=TRUE)
source('~/Git/Homework/DataScience/Assignment4/Bonus_partA.R', echo=TRUE)
source('~/Git/Homework/DataScience/Assignment4/pasatra_question5a.R', echo=TRUE)
source('~/Git/Homework/DataScience/Assignment4/Bonus_partB.R', echo=TRUE)
testData <- c(1,2,3,4,5,6,7,8,9,10)
testData
?stderr
?mean
?stats
library(help="stats")
summary(testData)
clear
stat(testData)
rm(testData)
mt1 = c(74 + 70 + 66 + 55 + 52 + 47 + 33)
mt2 = c(66 + 54 + 74 + 47 + 61 + 38 + 41)
reg_model = lm(formula = mt1 ~ mt2)
print(summary(reg_model))
mt1 = c(74 + 70 + 66 + 55 + 52 + 47 + 33)
mt2 = c(66 + 54 + 74 + 47 + 61 + 38 + 41)
reg_model = lm(formula = mt2 ~ mt1)
print(summary(reg_model))
mt1 = c(74, 70 , 66 , 55 , 52 , 47 , 33)
mt2 = c(66 , 54 , 74 , 47 , 61 , 38 , 41)
reg_model = lm(formula = mt2 ~ mt1)
print(summary(reg_model))
mt1 = c(74, 70 , 66 , 55 , 52 , 47 , 33)
mt2 = c(66 , 54 , 74 , 47 , 61 , 38 , 41)
reg_model = lm(formula = mt1 ~ mt2)
print(summary(reg_model))
mt1 = c(74, 70 , 66 , 55 , 52 , 47 , 33)
mt2 = c(66 , 54 , 74 , 47 , 61 , 38 , 41)
reg_model = lm(formula = mt2 ~ mt1)
print(summary(reg_model))
mt1 = c(74, 70 , 66 , 55 , 52 , 47 , 33)
mt2 = c(66 , 58 , 74 , 47 , 61 , 38 , 41)
reg_model = lm(formula = mt2 ~ mt1)
print(summary(reg_model))
setwd("~/Git/Homework/DataScience/Assignment5")
data <- read.csv("hw5-3d-data.csv", header = TRUE)
View(data)
length(data)
mean(data)
colMeans(data)
?kmeans
kmeans(data, data_mean)
kmeans(data, data_mean)
rm(list = ls())
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
data_mean <- colMeans(data)
kmeans(data, data_mean)
dim(data)
dim(data_mean)
dim(as.data.frame(data_mean))
as.data.frame(data_mean)
data_mean <- t(as.data.frame(colMeans(data)))
data_mean
rm(list = ls())
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
data_mean <- t(as.data.frame(colMeans(data)))
kmeans(data, data_mean)
nrow(data)
nrow(data_mean)
rm(list = ls())
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
data_mean <- t(as.data.frame(colMeans(data)))
kmeans(data, data_mean)
data_mean
names(data_mean) = NULL
kmeans(data, data_mean)
data_mean <- as.data.frame(t(colMeans(data)))
data_mean
kmeans(data, data_mean)
rm(list = ls())
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
data_mean <- as.data.frame(t(colMeans(data)))
kmeans(data, data_mean)
?kmeans
data_mean <- rbind(data_mean, as.data.frame(t(colMeans(data))))
data_mean
data_mean <- as.data.frame(t(colMeans(data)))
data_mean <- rbind(data_mean, as.data.frame(t(colMeans(data))))
kmeans(data, data_mean)
data_mean <- as.data.frame(t(colMeans(data)))
data_mean <- rbind(data_mean, as.data.frame(t(colSums(data))))
kmeans(data, data_mean)
rm(list = ls())
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
data_mean <- as.data.frame(t(colMeans(data)))
data_mean <- rbind(data_mean, as.data.frame(t(colSums(data))))
kmeans(data, data_mean)
rm(list = ls())
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
data_mean <- as.data.frame(t(colMeans(data)))
data_mean <- rbind(data_mean, as.data.frame(t(colSums(data)/100)))
kmeans(data, data_mean)
nrows(data)
nrow(data)
data <- read.csv("hw5-3d-data.csv", header = TRUE)
data_mean <- as.data.frame(t(colMeans(data)))
data_mean <- rbind(data_mean, as.data.frame(t(colSums(data)/1000)))
kmeans(data, data_mean)
clusters <- kmeans(data, 1)
rm(list = ls())
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
clusters <- kmeans(data, 1)
clusters
length(clusters)
clusters
length(clusters$centers)
clusters$cluster
clusters$centers[1]
clusters$centers[1,]
nrow(clusters$centers[1,])
nrow(clusters$centers)
data_set <- data[clusters[i] == i,]
for(i in 1:nrow(clusters$centers)) {
data_set <- data[clusters[i] == i,]
# Use a statistical test to detect if each data set follows a Gaussian distribution
}
data_set <- data[clusters[1] == 1,]
data_set <- data[clusters$cluster[1] == 1,]
data_set <- data[clusters$cluster[i] == 1,]
?prcomp
prcomp(data_set)
p_comp <- prcomp(data_set)
p_comp
p_comp$sdev[1]
lambda <- p_comp$sdev[1]
p_vector <- p_comp[,1]
p_comp <- prcomp(data_set)
lambda <- p_comp$sdev[1]
p_vector <- p_comp[,1]
p_vector <- p_comp$rotation[,1]
p_vector <- p_vector * sqrt(2 * lambda / pi)
p_vector
centers = clusters$centers[i,] - p_vector
centers
rbind(centers, clusters$centers[i,] + p_vector)
names(centers) = NULL
centers
rbind(centers, clusters$centers[i,] + p_vector)
centers[1,]
as.data.frame(centers)
centers = df[clusters$centers[i,] - p_vector]
centers = clusters$centers[i,] - p_vector
centers = df[clusters$centers[i,] - p_vector]
centers
centers = rbind(clusters$centers[i,] - p_vector, clusters$centers[i,] + p_vector)
centers
new_clusters <- kmeans(data_set, centers)
new_clusters
direction <- new_clusters$centers[1, ] - new_clusters$centers[2, ]
?norm
direction <- norm(direction, "F")
direction <- norm(direction, type = "F")
direction
direction <- norm(as.vector(direction), type = "F")
direction <- norm(direction, type = c("F"))
type(direction)
typeof(direction)
as.matrix(direction)
as.matrix(t(direction))
norm(as.matrix(t(direction)))
distance <- norm(as.matrix(t(direction)), "f")
distance
projection <- (data_set %*% direction) / (distance ^ 2)
projection <- (as.matrix(data_set) %*% direction) / (distance ^ 2)
nrow(proc.time())
nrow(projection
)
dim(projection)
?ecdf
ecdf_function <- edcf(projection)
install.packages("nortest")
library(nortest)
ecdf_function <- edcf(projection)
rm(list = ls())
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
clusters <- kmeans(data, 1)
alpha = 0.0001
# Set of datapoints assigned to center cj
for(i in 1:nrow(clusters$centers)) {
data_set <- data[clusters$cluster[i] == 1,]
data_set <- data[clusters$cluster[i] == i,]
rm(list = ls())
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
clusters <- kmeans(data, 1)
alpha = 0.0001
# Set of datapoints assigned to center cj
for(i in 1:nrow(clusters$centers)) {
data_set <- data[clusters$cluster[i] == i,]
# Use a statistical test to detect if each data set follows a Gaussian distribution
# Performing PCA to get new(better) centers
p_comp <- prcomp(data_set)
lambda <- p_comp$sdev[1]
p_vector <- p_comp$rotation[,1]
p_vector <- p_vector * sqrt(2 * lambda / pi)
new_centers = rbind(clusters$centers[i,] - p_vector, clusters$centers[i,] + p_vector)
# Run kmeans to get the new centers for the dataset
new_clusters <- kmeans(data_set, new_centers)
# Calculate direction between the two centers.
direction <- new_clusters$centers[1, ] - new_clusters$centers[2, ]
distance <- norm(as.matrix(t(direction)), "f")
# Project the data onto the new centers
projection <- (as.matrix(data_set) %*% direction) / (distance ^ 2)
projection <- scale(projection)
ecdf_function <- ecdf(projection)
}
data <- read.csv("hw5-3d-data.csv", header = TRUE)
clusters <- kmeans(data, 1)
alpha = 0.0001
data_set <- data[clusters$cluster[1] == 1,]
p_comp <- prcomp(data_set)
lambda <- p_comp$sdev[1]
p_vector <- p_comp$rotation[,1]
p_vector <- p_vector * sqrt(2 * lambda / pi)
new_centers = rbind(clusters$centers[i,] - p_vector, clusters$centers[i,] + p_vector)
new_clusters <- kmeans(data_set, new_centers)
direction <- new_clusters$centers[1, ] - new_clusters$centers[2, ]
distance <- norm(as.matrix(t(direction)), "f")
p_vector <- p_comp$rotation[,1]
p_vector <- p_vector * sqrt(2 * lambda / pi)
new_centers = rbind(clusters$centers[i,] - p_vector, clusters$centers[i,] + p_vector)
rm(list = ls())
data <- read.csv("hw5-3d-data.csv", header = TRUE)
rm(list = ls())
rm(list = ls())
rm(list = ls())
rm(list = ls())
)
rm(list = ls())
data <- read.csv("hw5-3d-data.csv", header = TRUE)
clusters <- kmeans(data, 1)
alpha = 0.0001
data_set <- data[clusters$cluster[1] == 1,]
# Use a statistical test to detect if each data set follows a Gaussian distribution
# Performing PCA to get new(better) centers
p_comp <- prcomp(data_set)
lambda <- p_comp$sdev[1]
p_vector <- p_comp$rotation[,1]
p_vector <- p_vector * sqrt(2 * lambda / pi)
new_centers = rbind(clusters$centers[i,] - p_vector, clusters$centers[i,] + p_vector)
new_clusters <- kmeans(data_set, new_centers)
# Calculate direction between the two centers.
direction <- new_clusters$centers[1, ] - new_clusters$centers[2, ]
distance <- norm(as.matrix(t(direction)), "f")
new_centers = rbind(clusters$centers[1,] - p_vector, clusters$centers[1,] + p_vector)
# Run kmeans to get the new centers for the dataset
new_clusters <- kmeans(data_set, new_centers)
# Calculate direction between the two centers.
direction <- new_clusters$centers[1, ] - new_clusters$centers[2, ]
distance <- norm(as.matrix(t(direction)), "f")
# Project the data onto the new centers
projection <- (as.matrix(data_set) %*% direction) / (distance ^ 2)
projection <- scale(projection)
ecdf_function <- ecdf(projection)
ecdf_values <- ecdf_function(projection)
?ad.test
ad <- ad.test(ecdf_values)
ad
next_centers = df[0, 3]
next_centers = data[0, ]
source('~/Git/Homework/DataScience/Assignment5/pasatra_q5.R', echo=TRUE)
install.packages("ADGofTest")
source('~/Git/Homework/DataScience/Assignment5/pasatra_q5.R', echo=TRUE)
source('~/Git/Homework/DataScience/Assignment5/pasatra_q5.R', echo=TRUE)
library(ADGofTest)
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
rm(list = ls())
library(ADGofTest)
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
alpha = 0.005
num_centers = 1;
centers = data[0, ]
clusters <- kmeans(data, 1)
# Run kmeans for the desired number of clusters
while(TRUE) {
if(num_centers != 1) {
clusters <- kmeans(data, centers = centers)
}
next_centers = data[0, ]
# Set of datapoints assigned to center cj
for(i in 1:nrow(clusters$centers)) {
data_set <- data[clusters$cluster[i] == i,]
# Use a statistical test to detect if each data set follows a Gaussian distribution
# Performing PCA to get new(better) centers
p_comp <- prcomp(data_set)
lambda <- p_comp$sdev[1]
p_vector <- p_comp$rotation[,1]
p_vector <- p_vector * sqrt(2 * lambda / pi)
new_centers = rbind(clusters$centers[i,] - p_vector, clusters$centers[i,] + p_vector)
# Run kmeans to get the new centers for the dataset
new_clusters <- kmeans(data_set, new_centers)
# Calculate direction between the two centers.
direction <- new_clusters$centers[1, ] - new_clusters$centers[2, ]
distance <- norm(as.matrix(t(direction)), "f")
# Project the data onto the new centers
projection <- (as.matrix(data_set) %*% direction) / (distance ^ 2)
projection <- scale(projection)
# Perform AD-Test
ad <- ad.test(projection, pnorm, 0, 1)
if(ad$p.value <= alpha) {
next_centers <- rbind(next_centers, new_clusters$centers)
} else {
next_centers <- rbind(next_centers, clusters$centers[i,])
}
}
centers <- next_centers
if(num_centers == nrow(centers)) {
break
} else {
num_centers = nrow(centers)
}
}
source('~/Git/Homework/DataScience/Assignment5/pasatra_q5.R', echo=TRUE)
rm(list = ls())
library(ADGofTest)
data <- read.csv("hw5-3d-data.csv", header = TRUE)
alpha = 0.005
num_centers = 1;
centers = data[0, ]
clusters <- kmeans(data, 1)
next_centers = data[0, ]
data_set <- data[clusters$cluster[1] == 1,]
p_comp <- prcomp(data_set)
lambda <- p_comp$sdev[1]
p_vector <- p_comp$rotation[,1]
p_vector <- p_vector * sqrt(2 * lambda / pi)
new_centers = rbind(clusters$centers[i,] - p_vector, clusters$centers[i,] + p_vector)
new_clusters <- kmeans(data_set, new_centers)
direction <- new_clusters$centers[1, ] - new_clusters$centers[2, ]
distance <- norm(as.matrix(t(direction)), "f")
rm(list = ls())
library(ADGofTest)
# Read data
data <- read.csv("hw5-3d-data.csv", header = TRUE)
alpha = 0.005
num_centers = 1;
centers = data[0, ]
clusters <- kmeans(data, 1)
next_centers = data[0, ]
i = 1
data_set <- data[clusters$cluster[i] == i,]
p_comp <- prcomp(data_set)
lambda <- p_comp$sdev[1]
p_vector <- p_comp$rotation[,1]
p_vector <- p_vector * sqrt(2 * lambda / pi)
new_centers = rbind(clusters$centers[i,] - p_vector, clusters$centers[i,] + p_vector)
new_clusters <- kmeans(data_set, new_centers)
direction <- new_clusters$centers[1, ] - new_clusters$centers[2, ]
distance <- norm(as.matrix(t(direction)), "f")
projection <- (as.matrix(data_set) %*% direction) / (distance ^ 2)
projection <- scale(projection)
ad <- ad.test(projection, pnorm)
ad$p.value
if(ad$p.value <= alpha) {
next_centers <- rbind(next_centers, new_clusters$centers)
} else {
next_centers <- rbind(next_centers, clusters$centers[i,])
}
next_centers
centers <- next_centers
num_centers = nrow(centers)
num_centers
clusters <- kmeans(data, centers = centers)
next_centers = data[0, ]
i = 1
data_set <- data[clusters$cluster[i] == i,]
p_comp <- prcomp(data_set)
lambda <- p_comp$sdev[1]
p_vector <- p_comp$rotation[,1]
p_vector <- p_vector * sqrt(2 * lambda / pi)
new_centers = rbind(clusters$centers[i,] - p_vector, clusters$centers[i,] + p_vector)
new_clusters <- kmeans(data_set, new_centers)
direction <- new_clusters$centers[1, ] - new_clusters$centers[2, ]
distance <- norm(as.matrix(t(direction)), "f")
projection <- (as.matrix(data_set) %*% direction) / (distance ^ 2)
projection <- scale(projection)
ad <- ad.test(projection, pnorm)
ad$p.value
next_centers <- rbind(next_centers, new_clusters$centers)
i = 2
next_centers
data_set <- data[clusters$cluster[i] == i,]
p_comp <- prcomp(data_set)
lambda <- p_comp$sdev[1]
p_vector <- p_comp$rotation[,1]
p_vector <- p_vector * sqrt(2 * lambda / pi)
new_centers = rbind(clusters$centers[i,] - p_vector, clusters$centers[i,] + p_vector)
new_clusters <- kmeans(data_set, new_centers)
direction <- new_clusters$centers[1, ] - new_clusters$centers[2, ]
distance <- norm(as.matrix(t(direction)), "f")
projection <- (as.matrix(data_set) %*% direction) / (distance ^ 2)
projection <- scale(projection)
ad <- ad.test(projection, pnorm)
new_centers
data_set
data_set <- data[clusters$cluster[i] == i,]
data_set
clusters
data_set <- data[clusters$cluster == i,]
data_set
source('~/Git/Homework/DataScience/Assignment5/pasatra_q5.R', echo=TRUE)
centers
final_cluster <- kmeans(data, centers)
?clusplot
install.packages("fpc")
?clusplot
library(fpc)
install.packages("cluster")
?clusplot
?clusplot
library(cluster)
?clusplot
plot(data, final_cluster$cluster)
plotcluster(data, final_cluster$cluster)
clusplot(data, final_cluster$cluster)
clusplot(data, final_cluster$cluster, lines = 3)
clusplot(data, final_cluster$cluster, lines = 3)
clusplot(data, final_cluster$cluster, lines = 3, cex = 0.5)
clusplot(data, final_cluster$cluster, lines = 3, cex = 0.7)
clusplot(data, final_cluster$cluster, lines = 3, cex = 0.7, color = TRUE)
clusplot(data, final_cluster$cluster, lines = 3, cex = 0.7, color = TRUE, col.p = TRUE)
clusplot(data, final_cluster$cluster, lines = 3, cex = 0.7, color = TRUE, col.p = c(2, 4, 5, 6))
clusplot(data, final_cluster$cluster, lines = 3, cex = 0.7, ccolor = TRUE,
main = "Gmeans")
clusplot(data, final_cluster$cluster, lines = 3, cex = 0.7, color = TRUE,
main = "Gmeans")
clusplot(data, final_cluster$cluster, lines = 3, cex = 0.7, color = TRUE,
main = "Gmeans", shade = TRUE)
clusplot(data, final_cluster$cluster, lines = 3, cex = 0.7, color = TRUE,
main = "Gmeans", shade = TRUE, xlab = "Principal Component 1",
ylab = "Principal Component 2")
clusplot(data, final_cluster$cluster, lines = 3, cex = 0.7, color = TRUE,
main = "G-Means", shade = TRUE, xlab = "Principal Component 1",
ylab = "Principal Component 2")
source('~/Git/Homework/DataScience/Assignment5/pasatra_q5.R', echo=TRUE)
source('~/Git/Homework/DataScience/Assignment5/pasatra_q5.R', echo=TRUE)
source('~/Git/Homework/DataScience/Assignment5/pasatra_q5.R', echo=TRUE)
source('~/Git/Homework/DataScience/Assignment5/pasatra_q5.R', echo=TRUE)
source('~/Git/Homework/DataScience/Assignment5/pasatra_q5.R', echo=TRUE)
source('~/Git/Homework/DataScience/Assignment5/pasatra_q5.R', echo=TRUE)
